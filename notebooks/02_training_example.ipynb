{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Training a Segmentation Model\n",
                "\n",
                "This notebook demonstrates how to train a segmentation model using the VLM evaluation framework."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "from pathlib import Path\n",
                "sys.path.insert(0, str(Path.cwd().parent))\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import DataLoader\n",
                "from tqdm.notebook import tqdm\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "from vlm_eval.core import EncoderRegistry, HeadRegistry, DatasetRegistry"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Create Model and Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create model\n",
                "encoder = EncoderRegistry.get(\"simple_cnn\", variant=\"small\", pretrained=False)\n",
                "model = HeadRegistry.get(\n",
                "    \"linear_probe\",\n",
                "    encoder=encoder,\n",
                "    num_classes=21,\n",
                "    freeze_encoder=False  # Train the whole model\n",
                ")\n",
                "\n",
                "# Create datasets\n",
                "train_dataset = DatasetRegistry.get(\"dummy\", num_samples=200, num_classes=21)\n",
                "val_dataset = DatasetRegistry.get(\"dummy\", num_samples=50, num_classes=21)\n",
                "\n",
                "# Create dataloaders\n",
                "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
                "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
                "\n",
                "print(f\"Model parameters: {model.get_num_parameters():,}\")\n",
                "print(f\"Training samples: {len(train_dataset)}\")\n",
                "print(f\"Validation samples: {len(val_dataset)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "model = model.to(device)\n",
                "\n",
                "# Loss and optimizer\n",
                "criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
                "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
                "\n",
                "print(f\"Device: {device}\")\n",
                "print(f\"Optimizer: {optimizer.__class__.__name__}\")\n",
                "print(f\"Learning rate: {optimizer.param_groups[0]['lr']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_epoch(model, loader, criterion, optimizer, device):\n",
                "    model.train()\n",
                "    total_loss = 0\n",
                "    \n",
                "    for batch in tqdm(loader, desc=\"Training\"):\n",
                "        images = batch[\"image\"].to(device)\n",
                "        masks = batch[\"mask\"].to(device)\n",
                "        \n",
                "        # Forward pass\n",
                "        features = model.encoder(images)\n",
                "        logits = model(features)\n",
                "        \n",
                "        # Compute loss\n",
                "        loss = criterion(logits, masks)\n",
                "        \n",
                "        # Backward pass\n",
                "        optimizer.zero_grad()\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        \n",
                "        total_loss += loss.item()\n",
                "    \n",
                "    return total_loss / len(loader)\n",
                "\n",
                "def validate(model, loader, criterion, device):\n",
                "    model.eval()\n",
                "    total_loss = 0\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for batch in tqdm(loader, desc=\"Validation\"):\n",
                "            images = batch[\"image\"].to(device)\n",
                "            masks = batch[\"mask\"].to(device)\n",
                "            \n",
                "            # Forward pass\n",
                "            features = model.encoder(images)\n",
                "            logits = model(features)\n",
                "            \n",
                "            # Compute loss\n",
                "            loss = criterion(logits, masks)\n",
                "            total_loss += loss.item()\n",
                "            \n",
                "            # Compute accuracy\n",
                "            preds = logits.argmax(dim=1)\n",
                "            correct += (preds == masks).sum().item()\n",
                "            total += masks.numel()\n",
                "    \n",
                "    avg_loss = total_loss / len(loader)\n",
                "    accuracy = correct / total\n",
                "    \n",
                "    return avg_loss, accuracy"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Train the Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "num_epochs = 5\n",
                "train_losses = []\n",
                "val_losses = []\n",
                "val_accuracies = []\n",
                "\n",
                "for epoch in range(num_epochs):\n",
                "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
                "    \n",
                "    # Train\n",
                "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
                "    train_losses.append(train_loss)\n",
                "    \n",
                "    # Validate\n",
                "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
                "    val_losses.append(val_loss)\n",
                "    val_accuracies.append(val_acc)\n",
                "    \n",
                "    print(f\"Train Loss: {train_loss:.4f}\")\n",
                "    print(f\"Val Loss: {val_loss:.4f}\")\n",
                "    print(f\"Val Accuracy: {val_acc:.4f}\")\n",
                "\n",
                "print(\"\\n✓ Training complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Plot Training Curves"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
                "\n",
                "# Loss\n",
                "axes[0].plot(train_losses, label='Train Loss', marker='o')\n",
                "axes[0].plot(val_losses, label='Val Loss', marker='s')\n",
                "axes[0].set_xlabel('Epoch')\n",
                "axes[0].set_ylabel('Loss')\n",
                "axes[0].set_title('Training and Validation Loss')\n",
                "axes[0].legend()\n",
                "axes[0].grid(True)\n",
                "\n",
                "# Accuracy\n",
                "axes[1].plot(val_accuracies, label='Val Accuracy', marker='o', color='green')\n",
                "axes[1].set_xlabel('Epoch')\n",
                "axes[1].set_ylabel('Accuracy')\n",
                "axes[1].set_title('Validation Accuracy')\n",
                "axes[1].legend()\n",
                "axes[1].grid(True)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Visualize Predictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.eval()\n",
                "batch = next(iter(val_loader))\n",
                "images = batch[\"image\"].to(device)\n",
                "masks = batch[\"mask\"].to(device)\n",
                "\n",
                "with torch.no_grad():\n",
                "    features = model.encoder(images)\n",
                "    logits = model(features)\n",
                "    predictions = logits.argmax(dim=1)\n",
                "\n",
                "# Show first 4 samples\n",
                "fig, axes = plt.subplots(4, 3, figsize=(12, 16))\n",
                "\n",
                "for i in range(4):\n",
                "    # Image\n",
                "    axes[i, 0].imshow(images[i].cpu().permute(1, 2, 0).numpy())\n",
                "    axes[i, 0].set_title(\"Input Image\")\n",
                "    axes[i, 0].axis('off')\n",
                "    \n",
                "    # Ground truth\n",
                "    axes[i, 1].imshow(masks[i].cpu().numpy(), cmap='tab20')\n",
                "    axes[i, 1].set_title(\"Ground Truth\")\n",
                "    axes[i, 1].axis('off')\n",
                "    \n",
                "    # Prediction\n",
                "    axes[i, 2].imshow(predictions[i].cpu().numpy(), cmap='tab20')\n",
                "    axes[i, 2].set_title(\"Prediction\")\n",
                "    axes[i, 2].axis('off')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Save Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save checkpoint\n",
                "checkpoint = {\n",
                "    'model_state_dict': model.state_dict(),\n",
                "    'optimizer_state_dict': optimizer.state_dict(),\n",
                "    'encoder_config': model.encoder.get_config(),\n",
                "    'head_config': model.get_config(),\n",
                "    'epoch': num_epochs,\n",
                "    'val_accuracy': val_accuracies[-1],\n",
                "}\n",
                "\n",
                "torch.save(checkpoint, 'model_checkpoint.pth')\n",
                "print(\"✓ Model saved to model_checkpoint.pth\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "You've successfully:\n",
                "1. ✅ Created a model with encoder and head\n",
                "2. ✅ Set up training and validation datasets\n",
                "3. ✅ Implemented training and validation loops\n",
                "4. ✅ Trained the model for multiple epochs\n",
                "5. ✅ Visualized training curves and predictions\n",
                "6. ✅ Saved the trained model\n",
                "\n",
                "This demonstrates the complete training workflow using the VLM evaluation framework!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}