{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VLM Evaluation Framework - Quick Start\n",
    "\n",
    "This notebook demonstrates how to use the VLM evaluation framework with a simple CNN encoder and dummy dataset.\n",
    "\n",
    "**No external data or pretrained weights required!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Import framework components\n",
    "from vlm_eval import EncoderRegistry, HeadRegistry, DatasetRegistry\n",
    "from vlm_eval.encoders import SimpleCNNEncoder\n",
    "from vlm_eval.heads import LinearProbeHead\n",
    "from vlm_eval.datasets import DummyDataset\n",
    "\n",
    "print(\"✓ Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Encoder\n",
    "\n",
    "The framework uses a registry system for easy model creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available encoders\n",
    "print(\"Available encoders:\", EncoderRegistry.list_available())\n",
    "\n",
    "# Create encoder\n",
    "encoder = EncoderRegistry.get(\"simple_cnn\", variant=\"base\", pretrained=False)\n",
    "\n",
    "print(f\"\\nEncoder: {encoder.__class__.__name__}\")\n",
    "print(f\"Output channels: {encoder.output_channels}\")\n",
    "print(f\"Patch size: {encoder.patch_size}\")\n",
    "print(f\"Parameters: {encoder.get_num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Segmentation Head\n",
    "\n",
    "The head takes encoder features and produces segmentation predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available heads\n",
    "print(\"Available heads:\", HeadRegistry.list_available())\n",
    "\n",
    "# Create head\n",
    "head = HeadRegistry.get(\n",
    "    \"linear_probe\",\n",
    "    encoder=encoder,\n",
    "    num_classes=21,\n",
    "    freeze_encoder=False\n",
    ")\n",
    "\n",
    "print(f\"\\nHead: {head.__class__.__name__}\")\n",
    "print(f\"Total parameters: {head.get_num_parameters():,}\")\n",
    "print(f\"Trainable parameters: {head.get_num_parameters(trainable_only=True):,}\")\n",
    "print(f\"Head-only parameters: {head.get_head_parameters():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Dataset\n",
    "\n",
    "For this demo, we use a dummy dataset that generates random images and masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available datasets\n",
    "print(\"Available datasets:\", DatasetRegistry.list_available())\n",
    "\n",
    "# Create dataset\n",
    "dataset = DatasetRegistry.get(\n",
    "    \"dummy\",\n",
    "    num_samples=50,\n",
    "    image_size=224,\n",
    "    num_classes=21\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset: {dataset.__class__.__name__}\")\n",
    "print(f\"Number of samples: {len(dataset)}\")\n",
    "print(f\"Number of classes: {dataset.num_classes}\")\n",
    "print(f\"Class names: {dataset.class_names[:5]}...\")  # Show first 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample\n",
    "sample = dataset[0]\n",
    "image = sample[\"image\"]\n",
    "mask = sample[\"mask\"]\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Image\n",
    "axes[0].imshow(image.permute(1, 2, 0).numpy())\n",
    "axes[0].set_title(f\"Image: {sample['filename']}\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Mask\n",
    "axes[1].imshow(mask.numpy(), cmap='tab20')\n",
    "axes[1].set_title(\"Segmentation Mask\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "print(f\"Mask shape: {mask.shape}\")\n",
    "print(f\"Unique classes in mask: {mask.unique().tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"DataLoader created with batch_size=4\")\n",
    "print(f\"Number of batches: {len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move model to device\n",
    "head = head.to(device)\n",
    "head.eval()\n",
    "\n",
    "# Get one batch\n",
    "batch = next(iter(dataloader))\n",
    "images = batch[\"image\"].to(device)\n",
    "masks = batch[\"mask\"].to(device)\n",
    "\n",
    "print(f\"\\nInput shapes:\")\n",
    "print(f\"  Images: {images.shape}\")\n",
    "print(f\"  Masks: {masks.shape}\")\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    features = encoder(images)\n",
    "    logits = head(features)\n",
    "    predictions = logits.argmax(dim=1)\n",
    "\n",
    "print(f\"\\nOutput shapes:\")\n",
    "print(f\"  Features: {features.shape}\")\n",
    "print(f\"  Logits: {logits.shape}\")\n",
    "print(f\"  Predictions: {predictions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize first sample in batch\n",
    "idx = 0\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Input image\n",
    "axes[0].imshow(images[idx].cpu().permute(1, 2, 0).numpy())\n",
    "axes[0].set_title(\"Input Image\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Ground truth mask\n",
    "axes[1].imshow(masks[idx].cpu().numpy(), cmap='tab20')\n",
    "axes[1].set_title(\"Ground Truth Mask\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Prediction\n",
    "axes[2].imshow(predictions[idx].cpu().numpy(), cmap='tab20')\n",
    "axes[2].set_title(\"Prediction (Random - Untrained)\")\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Note: Predictions are random since the model is untrained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Configuration-Based Usage\n",
    "\n",
    "The framework supports YAML configuration files for easy experiment management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from vlm_eval.core.config import ExperimentConfig\n",
    "\n",
    "# Load configuration\n",
    "config_path = project_root / \"configs\" / \"experiments\" / \"demo_simple_cnn.yaml\"\n",
    "\n",
    "with open(config_path) as f:\n",
    "    config_dict = yaml.safe_load(f)\n",
    "\n",
    "# Create config object\n",
    "config = ExperimentConfig(**config_dict)\n",
    "\n",
    "print(\"Experiment configuration:\")\n",
    "print(f\"  Name: {config.name}\")\n",
    "print(f\"  Encoder: {config.encoder.name} ({config.encoder.variant})\")\n",
    "print(f\"  Head: {config.head.name}\")\n",
    "print(f\"  Dataset: {config.dataset.name}\")\n",
    "print(f\"  Batch size: {config.inference.batch_size}\")\n",
    "print(f\"  Device: {config.inference.device}\")\n",
    "\n",
    "# Create models from config\n",
    "encoder_from_config = EncoderRegistry.from_config(config.encoder.model_dump())\n",
    "head_from_config = HeadRegistry.from_config(\n",
    "    config.head.model_dump(),\n",
    "    encoder=encoder_from_config\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Models created from configuration!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've successfully:\n",
    "1. ✅ Created an encoder using the registry system\n",
    "2. ✅ Created a segmentation head\n",
    "3. ✅ Loaded a dataset\n",
    "4. ✅ Run forward passes\n",
    "5. ✅ Visualized predictions\n",
    "6. ✅ Used configuration files\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Implement real encoders**: Add RADIO, DINOv2, or CLIP encoders\n",
    "2. **Add real datasets**: Implement Pascal VOC, ADE20K, or Cityscapes\n",
    "3. **Training**: Add training loops and optimization\n",
    "4. **Evaluation**: Implement mIoU and other metrics\n",
    "5. **Experiments**: Run full evaluation pipelines\n",
    "\n",
    "Check out the other notebooks for more examples!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
