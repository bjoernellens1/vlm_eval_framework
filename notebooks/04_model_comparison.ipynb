{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Model Comparison: SimpleCNN vs RADIO\n",
                "\n",
                "This notebook compares two different encoders for semantic segmentation:\n",
                "1. **SimpleCNN**: Lightweight CNN encoder (framework's baseline)\n",
                "2. **RADIO**: NVIDIA's foundation model (state-of-the-art)\n",
                "\n",
                "We'll compare:\n",
                "- Architecture and parameter counts\n",
                "- Inference speed\n",
                "- Prediction quality\n",
                "- Feature representations"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup and Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "from pathlib import Path\n",
                "\n",
                "# Add project to path\n",
                "project_root = Path.cwd().parent\n",
                "sys.path.insert(0, str(project_root))\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from torch.utils.data import DataLoader\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "from tqdm.notebook import tqdm\n",
                "import time\n",
                "\n",
                "# Import framework components\n",
                "from vlm_eval import EncoderRegistry, HeadRegistry, DatasetRegistry\n",
                "\n",
                "print(\"✓ Imports successful!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Dataset\n",
                "\n",
                "Using Pascal VOC with a small subset for comparison."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create dataset\n",
                "dataset = DatasetRegistry.get(\n",
                "    \"pascal_voc\",\n",
                "    root=\"./data/pascal_voc\",\n",
                "    split=\"val\",\n",
                "    download=True,\n",
                "    subset_size=30,\n",
                "    image_size=224  # Use 224 for fair comparison (both models support this)\n",
                ")\n",
                "\n",
                "dataloader = DataLoader(dataset, batch_size=4, shuffle=False, num_workers=0)\n",
                "\n",
                "print(f\"Dataset: {len(dataset)} samples\")\n",
                "print(f\"Batches: {len(dataloader)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Create Both Encoders\n",
                "\n",
                "Load SimpleCNN and RADIO encoders."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create SimpleCNN encoder\n",
                "print(\"Creating SimpleCNN encoder...\")\n",
                "encoder_cnn = EncoderRegistry.get(\"simple_cnn\", variant=\"base\", pretrained=False)\n",
                "\n",
                "# Create RADIO encoder\n",
                "print(\"\\nCreating RADIO encoder (may take a moment)...\")\n",
                "encoder_radio = EncoderRegistry.get(\"radio\", variant=\"base\", pretrained=True)\n",
                "\n",
                "print(\"\\n✓ Both encoders created successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Architecture Comparison\n",
                "\n",
                "Compare model architectures and parameter counts."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Gather architecture info\n",
                "comparison_data = {\n",
                "    \"Metric\": [\n",
                "        \"Model Name\",\n",
                "        \"Total Parameters\",\n",
                "        \"Parameters (M)\",\n",
                "        \"Output Channels\",\n",
                "        \"Patch Size\",\n",
                "        \"Pretrained\"\n",
                "    ],\n",
                "    \"SimpleCNN\": [\n",
                "        \"SimpleCNN (Base)\",\n",
                "        f\"{encoder_cnn.get_num_parameters():,}\",\n",
                "        f\"{encoder_cnn.get_num_parameters() / 1e6:.2f}M\",\n",
                "        encoder_cnn.output_channels,\n",
                "        encoder_cnn.patch_size,\n",
                "        \"No\"\n",
                "    ],\n",
                "    \"RADIO\": [\n",
                "        \"NVIDIA RADIO\",\n",
                "        f\"{encoder_radio.get_num_parameters():,}\",\n",
                "        f\"{encoder_radio.get_num_parameters() / 1e6:.2f}M\",\n",
                "        encoder_radio.output_channels,\n",
                "        encoder_radio.patch_size,\n",
                "        \"Yes (ImageNet+)\"\n",
                "    ]\n",
                "}\n",
                "\n",
                "df = pd.DataFrame(comparison_data)\n",
                "print(\"\\n=== Architecture Comparison ===\")\n",
                "print(df.to_string(index=False))\n",
                "\n",
                "# Visualize parameter counts\n",
                "fig, ax = plt.subplots(figsize=(10, 5))\n",
                "models = ['SimpleCNN', 'RADIO']\n",
                "params = [\n",
                "    encoder_cnn.get_num_parameters() / 1e6,\n",
                "    encoder_radio.get_num_parameters() / 1e6\n",
                "]\n",
                "colors = ['#3498db', '#e74c3c']\n",
                "\n",
                "bars = ax.bar(models, params, color=colors, alpha=0.7)\n",
                "ax.set_ylabel('Parameters (Millions)', fontsize=12)\n",
                "ax.set_title('Model Size Comparison', fontsize=14, fontweight='bold')\n",
                "ax.grid(axis='y', alpha=0.3)\n",
                "\n",
                "# Add value labels on bars\n",
                "for bar, param in zip(bars, params):\n",
                "    height = bar.get_height()\n",
                "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
                "            f'{param:.1f}M',\n",
                "            ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Create Segmentation Heads\n",
                "\n",
                "Add linear probe heads to both encoders."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create heads\n",
                "head_cnn = HeadRegistry.get(\n",
                "    \"linear_probe\",\n",
                "    encoder=encoder_cnn,\n",
                "    num_classes=21,\n",
                "    freeze_encoder=False\n",
                ")\n",
                "\n",
                "head_radio = HeadRegistry.get(\n",
                "    \"linear_probe\",\n",
                "    encoder=encoder_radio,\n",
                "    num_classes=21,\n",
                "    freeze_encoder=True  # Freeze RADIO for linear probing\n",
                ")\n",
                "\n",
                "print(\"SimpleCNN Head:\")\n",
                "print(f\"  Total params: {head_cnn.get_num_parameters():,}\")\n",
                "print(f\"  Trainable params: {head_cnn.get_num_parameters(trainable_only=True):,}\")\n",
                "\n",
                "print(\"\\nRADIO Head:\")\n",
                "print(f\"  Total params: {head_radio.get_num_parameters():,}\")\n",
                "print(f\"  Trainable params: {head_radio.get_num_parameters(trainable_only=True):,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Inference Speed Comparison\n",
                "\n",
                "Measure inference time for both models."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"Using device: {device}\")\n",
                "\n",
                "# Move models to device\n",
                "head_cnn = head_cnn.to(device)\n",
                "head_radio = head_radio.to(device)\n",
                "head_cnn.eval()\n",
                "head_radio.eval()\n",
                "\n",
                "# Get a test batch\n",
                "test_batch = next(iter(dataloader))\n",
                "test_images = test_batch[\"image\"].to(device)\n",
                "\n",
                "# Warmup\n",
                "with torch.no_grad():\n",
                "    _ = head_cnn(encoder_cnn(test_images))\n",
                "    _ = head_radio(encoder_radio(test_images))\n",
                "\n",
                "# Benchmark SimpleCNN\n",
                "num_runs = 20\n",
                "times_cnn = []\n",
                "with torch.no_grad():\n",
                "    for _ in range(num_runs):\n",
                "        start = time.time()\n",
                "        features = encoder_cnn(test_images)\n",
                "        _ = head_cnn(features)\n",
                "        if device.type == 'cuda':\n",
                "            torch.cuda.synchronize()\n",
                "        times_cnn.append(time.time() - start)\n",
                "\n",
                "# Benchmark RADIO\n",
                "times_radio = []\n",
                "with torch.no_grad():\n",
                "    for _ in range(num_runs):\n",
                "        start = time.time()\n",
                "        features = encoder_radio(test_images)\n",
                "        _ = head_radio(features)\n",
                "        if device.type == 'cuda':\n",
                "            torch.cuda.synchronize()\n",
                "        times_radio.append(time.time() - start)\n",
                "\n",
                "# Results\n",
                "avg_time_cnn = np.mean(times_cnn) * 1000  # Convert to ms\n",
                "avg_time_radio = np.mean(times_radio) * 1000\n",
                "\n",
                "print(f\"\\n=== Inference Speed (batch_size={test_images.shape[0]}) ===\")\n",
                "print(f\"SimpleCNN: {avg_time_cnn:.2f} ms/batch\")\n",
                "print(f\"RADIO: {avg_time_radio:.2f} ms/batch\")\n",
                "print(f\"Speedup: {avg_time_radio / avg_time_cnn:.2f}x slower (RADIO)\")\n",
                "\n",
                "# Visualize\n",
                "fig, ax = plt.subplots(figsize=(10, 5))\n",
                "models = ['SimpleCNN', 'RADIO']\n",
                "times = [avg_time_cnn, avg_time_radio]\n",
                "colors = ['#2ecc71', '#e67e22']\n",
                "\n",
                "bars = ax.bar(models, times, color=colors, alpha=0.7)\n",
                "ax.set_ylabel('Inference Time (ms)', fontsize=12)\n",
                "ax.set_title('Inference Speed Comparison', fontsize=14, fontweight='bold')\n",
                "ax.grid(axis='y', alpha=0.3)\n",
                "\n",
                "for bar, t in zip(bars, times):\n",
                "    height = bar.get_height()\n",
                "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
                "            f'{t:.1f}ms',\n",
                "            ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Side-by-Side Predictions\n",
                "\n",
                "Compare predictions from both models on the same images."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get predictions from both models\n",
                "batch = next(iter(dataloader))\n",
                "images = batch[\"image\"].to(device)\n",
                "masks = batch[\"mask\"].to(device)\n",
                "\n",
                "with torch.no_grad():\n",
                "    # SimpleCNN predictions\n",
                "    features_cnn = encoder_cnn(images)\n",
                "    logits_cnn = head_cnn(features_cnn)\n",
                "    preds_cnn = logits_cnn.argmax(dim=1)\n",
                "    \n",
                "    # RADIO predictions\n",
                "    features_radio = encoder_radio(images)\n",
                "    logits_radio = head_radio(features_radio)\n",
                "    preds_radio = logits_radio.argmax(dim=1)\n",
                "\n",
                "# Visualize first 2 samples\n",
                "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
                "\n",
                "for i in range(2):\n",
                "    # Input image\n",
                "    axes[i, 0].imshow(images[i].cpu().permute(1, 2, 0).numpy())\n",
                "    axes[i, 0].set_title(\"Input Image\", fontsize=10)\n",
                "    axes[i, 0].axis('off')\n",
                "    \n",
                "    # Ground truth\n",
                "    axes[i, 1].imshow(masks[i].cpu().numpy(), cmap='tab20', vmin=0, vmax=20)\n",
                "    axes[i, 1].set_title(\"Ground Truth\", fontsize=10)\n",
                "    axes[i, 1].axis('off')\n",
                "    \n",
                "    # SimpleCNN prediction\n",
                "    axes[i, 2].imshow(preds_cnn[i].cpu().numpy(), cmap='tab20', vmin=0, vmax=20)\n",
                "    axes[i, 2].set_title(\"SimpleCNN Pred\", fontsize=10)\n",
                "    axes[i, 2].axis('off')\n",
                "    \n",
                "    # RADIO prediction\n",
                "    axes[i, 3].imshow(preds_radio[i].cpu().numpy(), cmap='tab20', vmin=0, vmax=20)\n",
                "    axes[i, 3].set_title(\"RADIO Pred\", fontsize=10)\n",
                "    axes[i, 3].axis('off')\n",
                "\n",
                "plt.suptitle(\"Model Comparison: Predictions (Untrained Heads)\", fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"Note: Both heads are untrained, so predictions are random.\")\n",
                "print(\"After training, RADIO typically shows superior performance.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Feature Comparison\n",
                "\n",
                "Compare the spatial features extracted by both encoders."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get features from both encoders\n",
                "sample_idx = 0\n",
                "sample_image = images[sample_idx:sample_idx+1]\n",
                "\n",
                "with torch.no_grad():\n",
                "    features_cnn = encoder_cnn(sample_image)\n",
                "    features_radio = encoder_radio(sample_image)\n",
                "\n",
                "# Visualize feature maps\n",
                "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
                "\n",
                "# Original image\n",
                "axes[0, 0].imshow(sample_image[0].cpu().permute(1, 2, 0).numpy())\n",
                "axes[0, 0].set_title(\"Input Image\", fontsize=11, fontweight='bold')\n",
                "axes[0, 0].axis('off')\n",
                "for j in range(1, 4):\n",
                "    axes[0, j].axis('off')\n",
                "\n",
                "# SimpleCNN features\n",
                "feat_cnn = features_cnn[0].cpu().numpy()\n",
                "for j in range(4):\n",
                "    axes[1, j].imshow(feat_cnn[j], cmap='viridis')\n",
                "    axes[1, j].set_title(f\"SimpleCNN Ch{j}\", fontsize=10)\n",
                "    axes[1, j].axis('off')\n",
                "\n",
                "# RADIO features\n",
                "feat_radio = features_radio[0].cpu().numpy()\n",
                "for j in range(4):\n",
                "    axes[2, j].imshow(feat_radio[j], cmap='viridis')\n",
                "    axes[2, j].set_title(f\"RADIO Ch{j}\", fontsize=10)\n",
                "    axes[2, j].axis('off')\n",
                "\n",
                "plt.suptitle(\"Feature Map Comparison (First 4 Channels)\", fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(f\"SimpleCNN feature shape: {features_cnn.shape}\")\n",
                "print(f\"RADIO feature shape: {features_radio.shape}\")\n",
                "print(f\"\\nRADIO has {features_radio.shape[1] / features_cnn.shape[1]:.1f}x more channels\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Summary Comparison Table\n",
                "\n",
                "Comprehensive comparison of all metrics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "summary_data = {\n",
                "    \"Metric\": [\n",
                "        \"Parameters (M)\",\n",
                "        \"Output Channels\",\n",
                "        \"Spatial Resolution\",\n",
                "        \"Inference Time (ms)\",\n",
                "        \"Pretrained\",\n",
                "        \"Best Use Case\"\n",
                "    ],\n",
                "    \"SimpleCNN\": [\n",
                "        f\"{encoder_cnn.get_num_parameters() / 1e6:.2f}M\",\n",
                "        encoder_cnn.output_channels,\n",
                "        f\"{features_cnn.shape[2]}x{features_cnn.shape[3]}\",\n",
                "        f\"{avg_time_cnn:.1f}\",\n",
                "        \"No\",\n",
                "        \"Fast inference, limited data\"\n",
                "    ],\n",
                "    \"RADIO\": [\n",
                "        f\"{encoder_radio.get_num_parameters() / 1e6:.2f}M\",\n",
                "        encoder_radio.output_channels,\n",
                "        f\"{features_radio.shape[2]}x{features_radio.shape[3]}\",\n",
                "        f\"{avg_time_radio:.1f}\",\n",
                "        \"Yes (Foundation)\",\n",
                "        \"Best accuracy, rich features\"\n",
                "    ]\n",
                "}\n",
                "\n",
                "df_summary = pd.DataFrame(summary_data)\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"COMPREHENSIVE MODEL COMPARISON\")\n",
                "print(\"=\"*60)\n",
                "print(df_summary.to_string(index=False))\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "### Key Findings\n",
                "\n",
                "**SimpleCNN:**\n",
                "- ✅ **Fast**: Much faster inference time\n",
                "- ✅ **Lightweight**: Fewer parameters, less memory\n",
                "- ✅ **Simple**: Easy to train from scratch\n",
                "- ❌ **Limited**: Lower capacity, no pretrained weights\n",
                "\n",
                "**RADIO:**\n",
                "- ✅ **Powerful**: State-of-the-art foundation model\n",
                "- ✅ **Rich Features**: High-dimensional spatial features\n",
                "- ✅ **Pretrained**: Excellent transfer learning\n",
                "- ❌ **Slower**: Higher computational cost\n",
                "- ❌ **Large**: More parameters and memory\n",
                "\n",
                "### When to Use Each Model\n",
                "\n",
                "**Use SimpleCNN when:**\n",
                "- You need fast inference\n",
                "- You have limited computational resources\n",
                "- You're prototyping or testing the framework\n",
                "- You have a simple segmentation task\n",
                "\n",
                "**Use RADIO when:**\n",
                "- You need best possible accuracy\n",
                "- You have limited training data (leverage pretrained features)\n",
                "- You're working on challenging segmentation tasks\n",
                "- Computational cost is not a primary concern\n",
                "\n",
                "### Next Steps\n",
                "\n",
                "1. **Train both models**: Compare performance after training\n",
                "2. **Try other encoders**: DINOv2, CLIP, SAM, etc.\n",
                "3. **Experiment with datasets**: Test on different segmentation benchmarks\n",
                "4. **Optimize inference**: Quantization, pruning, distillation\n",
                "\n",
                "The VLM evaluation framework makes it easy to swap encoders and compare them fairly!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}