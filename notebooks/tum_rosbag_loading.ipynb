{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# TUM Rosbag Loading and Model Comparison\n",
                "\n",
                "This notebook demonstrates how to load TUM dataset rosbags and compare `embed_slam` models on the sequence."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import matplotlib.pyplot as plt\n",
                "from PIL import Image\n",
                "import numpy as np\n",
                "import os\n",
                "\n",
                "from vlm_eval.core import EncoderRegistry, DatasetRegistry\n",
                "from vlm_eval.encoders import *\n",
                "from vlm_eval.datasets.tum_rosbag import TUMRosbagDataset\n",
                "\n",
                "# Ensure models are registered\n",
                "print(\"Available encoders:\", EncoderRegistry.list_available())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configuration\n",
                "bag_path = \"/home/jovyan/cps_persistent1_shared/datasets/public/TUM/rgbd_dataset_freiburg1_room.bag\" # Update this path\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "\n",
                "if not os.path.exists(bag_path):\n",
                "    print(f\"Warning: Bag file not found at {bag_path}. Please update the path.\")\n",
                "else:\n",
                "    # Load Dataset\n",
                "    dataset = TUMRosbagDataset(bag_path, topics=[\"/camera/rgb/image_color\"])\n",
                "    print(f\"Loaded dataset with {len(dataset)} frames.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading concept_fusion...\n",
                        "Failed to load concept_fusion: name 'EncoderRegistry' is not defined\n",
                        "Loading dino_fusion...\n",
                        "Failed to load dino_fusion: name 'EncoderRegistry' is not defined\n",
                        "Loading x_fusion...\n",
                        "Failed to load x_fusion: name 'EncoderRegistry' is not defined\n",
                        "Loading naradio_fusion...\n",
                        "Failed to load naradio_fusion: name 'EncoderRegistry' is not defined\n"
                    ]
                }
            ],
            "source": [
                "# Load Models\n",
                "models = {}\n",
                "model_names = [\"concept_fusion\", \"dino_fusion\", \"x_fusion\", \"naradio_fusion\"]\n",
                "\n",
                "for name in model_names:\n",
                "    try:\n",
                "        print(f\"Loading {name}...\")\n",
                "        models[name] = EncoderRegistry.get(name, device=device)\n",
                "        print(f\"Loaded {name}\")\n",
                "    except Exception as e:\n",
                "        print(f\"Failed to load {name}: {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize and Compare on a Frame\n",
                "frame_idx = 0\n",
                "text_query = \"chair\"\n",
                "\n",
                "if os.path.exists(bag_path):\n",
                "    data = dataset[frame_idx]\n",
                "    image_tensor = data[\"image\"].unsqueeze(0).to(device)\n",
                "    \n",
                "    # Display Image\n",
                "    plt.figure(figsize=(5, 5))\n",
                "    img_np = image_tensor[0].permute(1, 2, 0).cpu().numpy()\n",
                "    plt.imshow(img_np)\n",
                "    plt.title(f\"Frame {frame_idx}\")\n",
                "    plt.axis(\"off\")\n",
                "    plt.show()\n",
                "    \n",
                "    # Run Models\n",
                "    fig, axes = plt.subplots(1, len(models), figsize=(20, 5))\n",
                "    if len(models) == 1:\n",
                "        axes = [axes]\n",
                "        \n",
                "    for i, (name, model) in enumerate(models.items()):\n",
                "        print(f\"Running {name}...\")\n",
                "        with torch.no_grad():\n",
                "            features = model(image_tensor)\n",
                "            text_emb = model.encode_text([text_query])\n",
                "            sim = torch.einsum(\"bchw,bc->bhw\", features, text_emb)\n",
                "            sim_map = sim[0].cpu().numpy()\n",
                "            \n",
                "            axes[i].imshow(sim_map, cmap=\"jet\")\n",
                "            axes[i].set_title(f\"{name} - '{text_query}'\")\n",
                "            axes[i].axis(\"off\")\n",
                "        torch.cuda.empty_cache()\n",
                "            \n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
