{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Zero-Shot Classification with CLIP\n",
                "\n",
                "This notebook demonstrates how to use the VLM evaluation framework for zero-shot classification using CLIP.\n",
                "We will query the model with arbitrary class names and see how it classifies images."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup and Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "from pathlib import Path\n",
                "\n",
                "# Add project to path\n",
                "project_root = Path.cwd().parent\n",
                "sys.path.insert(0, str(project_root))\n",
                "\n",
                "import torch\n",
                "import matplotlib.pyplot as plt\n",
                "from PIL import Image\n",
                "import requests\n",
                "from io import BytesIO\n",
                "\n",
                "# Import framework components\n",
                "from vlm_eval import EncoderRegistry, HeadRegistry\n",
                "from vlm_eval.encoders import CLIPEncoder\n",
                "from vlm_eval.heads import ZeroShotHead\n",
                "\n",
                "print(\"✓ Imports successful!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load CLIP Encoder\n",
                "\n",
                "We'll use the ViT-B-32 variant of CLIP."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create encoder\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"Using device: {device}\")\n",
                "\n",
                "encoder = EncoderRegistry.get(\n",
                "    \"clip\", \n",
                "    variant=\"ViT-B-32\", \n",
                "    pretrained=\"laion2b_s34b_b79k\"\n",
                ")\n",
                "encoder = encoder.to(device)\n",
                "encoder.eval()\n",
                "\n",
                "print(f\"\\nEncoder: {encoder.__class__.__name__}\")\n",
                "print(f\"Output channels: {encoder.output_channels}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Define Classes and Create Head\n",
                "\n",
                "Here we define the classes we want to query. You can change these to anything!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define arbitrary classes\n",
                "class_names = [\n",
                "    \"a dog\",\n",
                "    \"a cat\",\n",
                "    \"a car\",\n",
                "    \"a bicycle\",\n",
                "    \"a person\",\n",
                "    \"a tree\"\n",
                "]\n",
                "\n",
                "print(f\"Classes: {class_names}\")\n",
                "\n",
                "# Create zero-shot head\n",
                "head = HeadRegistry.get(\n",
                "    \"zero_shot\",\n",
                "    encoder=encoder,\n",
                "    class_names=class_names,\n",
                "    template=\"{}\"  # We already included 'a' in class names, or use default template\n",
                ")\n",
                "head = head.to(device)\n",
                "\n",
                "print(\"✓ Zero-shot head created and text embeddings computed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Load and Preprocess Image\n",
                "\n",
                "We'll load an image from a URL."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load image\n",
                "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"  # Cats image\n",
                "response = requests.get(url)\n",
                "image = Image.open(BytesIO(response.content))\n",
                "\n",
                "# Display image\n",
                "plt.figure(figsize=(8, 8))\n",
                "plt.imshow(image)\n",
                "plt.axis('off')\n",
                "plt.show()\n",
                "\n",
                "# Preprocess\n",
                "# CLIP encoder has a preprocess method from open_clip\n",
                "image_tensor = encoder.preprocess(image).unsqueeze(0).to(device)\n",
                "print(f\"Image tensor shape: {image_tensor.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Run Prediction\n",
                "\n",
                "We'll get the logits and convert them to probabilities."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "with torch.no_grad():\n",
                "    # Encoder forward pass\n",
                "    features = encoder(image_tensor)\n",
                "    \n",
                "    # Head forward pass\n",
                "    logits = head(features)\n",
                "    \n",
                "    # Softmax to get probabilities\n",
                "    probs = logits.softmax(dim=-1)\n",
                "\n",
                "# Print results\n",
                "print(\"\\nPredictions:\")\n",
                "for cls, prob in zip(class_names, probs[0]):\n",
                "    print(f\"{cls}: {prob.item():.2%}\")\n",
                "    \n",
                "# Plot probabilities\n",
                "plt.figure(figsize=(10, 5))\n",
                "plt.bar(class_names, probs[0].cpu().numpy())\n",
                "plt.title(\"Class Probabilities\")\n",
                "plt.ylabel(\"Probability\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Try with different classes\n",
                "\n",
                "Let's try a different set of classes on the same image."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "new_classes = [\"indoor\", \"outdoor\", \"animal\", \"vehicle\", \"furniture\"]\n",
                "\n",
                "# Create new head (fast since we just compute text embeddings)\n",
                "head2 = HeadRegistry.get(\n",
                "    \"zero_shot\",\n",
                "    encoder=encoder,\n",
                "    class_names=new_classes\n",
                ").to(device)\n",
                "\n",
                "with torch.no_grad():\n",
                "    logits2 = head2(features)\n",
                "    probs2 = logits2.softmax(dim=-1)\n",
                "\n",
                "print(\"\\nNew Predictions:\")\n",
                "for cls, prob in zip(new_classes, probs2[0]):\n",
                "    print(f\"{cls}: {prob.item():.2%}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}