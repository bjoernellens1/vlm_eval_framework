{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# RADIO Encoder Evaluation\n",
                "\n",
                "This notebook demonstrates how to use NVIDIA's RADIO (Reduce All Domains Into One) encoder for semantic segmentation.\n",
                "\n",
                "**Requirements:**\n",
                "- Hugging Face authentication: Run `huggingface-cli login` before starting\n",
                "- ~2GB download for RADIO model (first time only)\n",
                "- ~450MB download for Pascal VOC dataset (first time only)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup and Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "from pathlib import Path\n",
                "\n",
                "# Add project to path\n",
                "project_root = Path.cwd().parent\n",
                "sys.path.insert(0, str(project_root))\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from torch.utils.data import DataLoader\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "from tqdm.notebook import tqdm\n",
                "\n",
                "# Import framework components\n",
                "from vlm_eval import EncoderRegistry, HeadRegistry, DatasetRegistry\n",
                "from vlm_eval.encoders import RADIOEncoder\n",
                "from vlm_eval.heads import LinearProbeHead\n",
                "from vlm_eval.datasets import PascalVOCDataset\n",
                "\n",
                "print(\"✓ Imports successful!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Pascal VOC Dataset\n",
                "\n",
                "We'll use a subset of 50 images for faster testing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# List available datasets\n",
                "print(\"Available datasets:\", DatasetRegistry.list_available())\n",
                "\n",
                "# Create dataset (subset of 50 images)\n",
                "dataset = DatasetRegistry.get(\n",
                "    \"pascal_voc\",\n",
                "    root=\"./data/pascal_voc\",\n",
                "    split=\"val\",\n",
                "    download=True,\n",
                "    subset_size=50,\n",
                "    image_size=518  # RADIO's recommended size for segmentation\n",
                ")\n",
                "\n",
                "print(f\"\\nDataset: {dataset.__class__.__name__}\")\n",
                "print(f\"Number of samples: {len(dataset)}\")\n",
                "print(f\"Number of classes: {dataset.num_classes}\")\n",
                "print(f\"Class names: {dataset.class_names[:5]}...\")  # Show first 5"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Visualize Dataset Samples"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get a sample\n",
                "sample = dataset[0]\n",
                "image = sample[\"image\"]\n",
                "mask = sample[\"mask\"]\n",
                "\n",
                "# Visualize\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
                "\n",
                "# Image\n",
                "axes[0].imshow(image.permute(1, 2, 0).numpy())\n",
                "axes[0].set_title(f\"Image: {sample['filename']}\")\n",
                "axes[0].axis('off')\n",
                "\n",
                "# Mask\n",
                "axes[1].imshow(mask.numpy(), cmap='tab20', vmin=0, vmax=20)\n",
                "axes[1].set_title(\"Segmentation Mask\")\n",
                "axes[1].axis('off')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(f\"Image shape: {image.shape}\")\n",
                "print(f\"Mask shape: {mask.shape}\")\n",
                "print(f\"Unique classes in mask: {mask.unique().tolist()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Create RADIO Encoder\n",
                "\n",
                "Load NVIDIA's RADIO model from Hugging Face."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# List available encoders\n",
                "print(\"Available encoders:\", EncoderRegistry.list_available())\n",
                "\n",
                "# Create RADIO encoder\n",
                "print(\"\\nLoading RADIO encoder (this may take a moment on first run)...\")\n",
                "encoder = EncoderRegistry.get(\"radio\", variant=\"base\", pretrained=True)\n",
                "\n",
                "print(f\"\\nEncoder: {encoder.__class__.__name__}\")\n",
                "print(f\"Output channels: {encoder.output_channels}\")\n",
                "print(f\"Patch size: {encoder.patch_size}\")\n",
                "print(f\"Parameters: {encoder.get_num_parameters():,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Create Segmentation Head\n",
                "\n",
                "Add a linear probe head for semantic segmentation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# List available heads\n",
                "print(\"Available heads:\", HeadRegistry.list_available())\n",
                "\n",
                "# Create head\n",
                "head = HeadRegistry.get(\n",
                "    \"linear_probe\",\n",
                "    encoder=encoder,\n",
                "    num_classes=21,  # Pascal VOC has 21 classes\n",
                "    freeze_encoder=True  # Freeze RADIO weights for linear probing\n",
                ")\n",
                "\n",
                "print(f\"\\nHead: {head.__class__.__name__}\")\n",
                "print(f\"Total parameters: {head.get_num_parameters():,}\")\n",
                "print(f\"Trainable parameters: {head.get_num_parameters(trainable_only=True):,}\")\n",
                "print(f\"Head-only parameters: {head.get_head_parameters():,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Create DataLoader"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataloader = DataLoader(\n",
                "    dataset,\n",
                "    batch_size=2,  # Small batch size for RADIO (large model)\n",
                "    shuffle=False,\n",
                "    num_workers=0\n",
                ")\n",
                "\n",
                "print(f\"DataLoader created with batch_size=2\")\n",
                "print(f\"Number of batches: {len(dataloader)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Run Forward Pass\n",
                "\n",
                "Test the RADIO encoder and segmentation head."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup device\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"Using device: {device}\")\n",
                "\n",
                "# Move model to device\n",
                "head = head.to(device)\n",
                "head.eval()\n",
                "\n",
                "# Get one batch\n",
                "batch = next(iter(dataloader))\n",
                "images = batch[\"image\"].to(device)\n",
                "masks = batch[\"mask\"].to(device)\n",
                "\n",
                "print(f\"\\nInput shapes:\")\n",
                "print(f\"  Images: {images.shape}\")\n",
                "print(f\"  Masks: {masks.shape}\")\n",
                "\n",
                "# Forward pass\n",
                "print(\"\\nRunning forward pass...\")\n",
                "with torch.no_grad():\n",
                "    features = encoder(images)\n",
                "    logits = head(features)\n",
                "    predictions = logits.argmax(dim=1)\n",
                "\n",
                "print(f\"\\nOutput shapes:\")\n",
                "print(f\"  Features: {features.shape}\")\n",
                "print(f\"  Logits: {logits.shape}\")\n",
                "print(f\"  Predictions: {predictions.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Visualize RADIO Features\n",
                "\n",
                "Visualize the spatial features extracted by RADIO."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize feature maps (first 6 channels)\n",
                "idx = 0  # First image in batch\n",
                "feature_maps = features[idx].cpu().numpy()\n",
                "\n",
                "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
                "axes = axes.flatten()\n",
                "\n",
                "for i in range(6):\n",
                "    axes[i].imshow(feature_maps[i], cmap='viridis')\n",
                "    axes[i].set_title(f\"Feature Channel {i}\")\n",
                "    axes[i].axis('off')\n",
                "\n",
                "plt.suptitle(\"RADIO Spatial Features (First 6 Channels)\", fontsize=14)\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(f\"Feature map shape: {feature_maps.shape}\")\n",
                "print(f\"Feature value range: [{feature_maps.min():.3f}, {feature_maps.max():.3f}]\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Visualize Predictions\n",
                "\n",
                "Compare input images, ground truth masks, and model predictions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize both samples in batch\n",
                "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
                "\n",
                "for i in range(2):\n",
                "    # Input image\n",
                "    axes[i, 0].imshow(images[i].cpu().permute(1, 2, 0).numpy())\n",
                "    axes[i, 0].set_title(\"Input Image\")\n",
                "    axes[i, 0].axis('off')\n",
                "    \n",
                "    # Ground truth mask\n",
                "    axes[i, 1].imshow(masks[i].cpu().numpy(), cmap='tab20', vmin=0, vmax=20)\n",
                "    axes[i, 1].set_title(\"Ground Truth\")\n",
                "    axes[i, 1].axis('off')\n",
                "    \n",
                "    # Prediction\n",
                "    axes[i, 2].imshow(predictions[i].cpu().numpy(), cmap='tab20', vmin=0, vmax=20)\n",
                "    axes[i, 2].set_title(\"Prediction (Untrained)\")\n",
                "    axes[i, 2].axis('off')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"Note: Predictions are random since the head is untrained.\")\n",
                "print(\"Training the linear probe head would improve these predictions significantly.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Calculate Evaluation Metrics\n",
                "\n",
                "Compute IoU and pixel accuracy on the validation subset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_iou(pred, target, num_classes=21, ignore_index=255):\n",
                "    \"\"\"Compute mean Intersection over Union.\"\"\"\n",
                "    ious = []\n",
                "    pred = pred.flatten()\n",
                "    target = target.flatten()\n",
                "    \n",
                "    for cls in range(num_classes):\n",
                "        pred_mask = pred == cls\n",
                "        target_mask = target == cls\n",
                "        \n",
                "        intersection = (pred_mask & target_mask).sum().float()\n",
                "        union = (pred_mask | target_mask).sum().float()\n",
                "        \n",
                "        if union > 0:\n",
                "            ious.append((intersection / union).item())\n",
                "    \n",
                "    return np.mean(ious) if ious else 0.0\n",
                "\n",
                "def compute_pixel_accuracy(pred, target, ignore_index=255):\n",
                "    \"\"\"Compute pixel accuracy.\"\"\"\n",
                "    valid_mask = target != ignore_index\n",
                "    correct = (pred[valid_mask] == target[valid_mask]).sum()\n",
                "    total = valid_mask.sum()\n",
                "    return (correct / total).item() if total > 0 else 0.0\n",
                "\n",
                "# Evaluate on a few batches\n",
                "head.eval()\n",
                "ious = []\n",
                "pixel_accs = []\n",
                "\n",
                "print(\"Evaluating on validation subset...\")\n",
                "with torch.no_grad():\n",
                "    for i, batch in enumerate(tqdm(dataloader)):\n",
                "        if i >= 10:  # Evaluate on first 10 batches\n",
                "            break\n",
                "        \n",
                "        images = batch[\"image\"].to(device)\n",
                "        masks = batch[\"mask\"].to(device)\n",
                "        \n",
                "        features = encoder(images)\n",
                "        logits = head(features)\n",
                "        predictions = logits.argmax(dim=1)\n",
                "        \n",
                "        # Compute metrics\n",
                "        for j in range(predictions.shape[0]):\n",
                "            iou = compute_iou(predictions[j], masks[j])\n",
                "            pixel_acc = compute_pixel_accuracy(predictions[j], masks[j])\n",
                "            ious.append(iou)\n",
                "            pixel_accs.append(pixel_acc)\n",
                "\n",
                "print(f\"\\nResults (untrained model):\")\n",
                "print(f\"Mean IoU: {np.mean(ious):.4f}\")\n",
                "print(f\"Pixel Accuracy: {np.mean(pixel_accs):.4f}\")\n",
                "print(\"\\nNote: These are baseline metrics for an untrained head.\")\n",
                "print(\"After training, RADIO typically achieves 70-80% mIoU on Pascal VOC.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "You've successfully:\n",
                "1. ✅ Loaded Pascal VOC dataset with subset mode\n",
                "2. ✅ Created NVIDIA's RADIO encoder from Hugging Face\n",
                "3. ✅ Added a linear probe segmentation head\n",
                "4. ✅ Run forward passes and extracted spatial features\n",
                "5. ✅ Visualized RADIO features and predictions\n",
                "6. ✅ Calculated evaluation metrics (IoU, pixel accuracy)\n",
                "\n",
                "### Next Steps\n",
                "\n",
                "1. **Train the linear probe head**: Fine-tune the segmentation head on Pascal VOC\n",
                "2. **Compare with other encoders**: See `04_model_comparison.ipynb`\n",
                "3. **Try different datasets**: ADE20K, Cityscapes, etc.\n",
                "4. **Experiment with input sizes**: RADIO supports flexible resolutions\n",
                "\n",
                "### Key Takeaways\n",
                "\n",
                "- **RADIO** is a powerful vision foundation model from NVIDIA\n",
                "- It provides rich **spatial features** suitable for dense prediction tasks\n",
                "- The framework makes it easy to **swap encoders** and compare performance\n",
                "- **Linear probing** is an efficient way to evaluate encoder quality"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}